{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "from urllib.request import urlopen, Request\r\n",
                "from bs4 import BeautifulSoup\r\n",
                "from nltk.sentiment.vader import SentimentIntensityAnalyzer\r\n",
                "import pandas as pd\r\n",
                "import matplotlib.pyplot as plt\r\n",
                "import nltk\r\n",
                "nltk.downloader.download('vader_lexicon')"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "finviz_url = 'https://finviz.com/quote.ashx?t='\r\n",
                "Companys = ['AMZN', 'GOOG', 'FB'] # stock companies\r\n",
                "\r\n",
                "news_tables = {} # Declare empty dictionary to store results from finviz\r\n",
                "\r\n",
                "for Company in Companys:\r\n",
                "    url = finviz_url + Company\r\n",
                "    req = Request(url=url, headers={'user-agent':'my-app'}) # Specify headers or else access will be denied\r\n",
                "    response = urlopen(req)\r\n",
                "    soup = BeautifulSoup(response,features='html.parser')\r\n",
                "    news_table = soup.find(id='news-table')\r\n",
                "    # We get table rows\r\n",
                "    # We get text on on td tag\r\n",
                "    # We get time stamp on tr tag\r\n",
                "    news_tables.update({Company:news_table}) # Key ticker (Company name) and value news_table\r\n",
                "    \r\n",
                "\r\n",
                "parsed_data = [] # Instantiate new list object\r\n",
                "\r\n",
                "for Company, news_table in news_tables.items(): # This will iterate over all keys and values using the .tems() function\r\n",
                "    for row in news_table.find_all('tr'):\r\n",
                "        Comments = row.a.text\r\n",
                "        date_data = row.td.text.split(' ') # Split date with space \r\n",
                "        # If loop to determine if date is made of 1 or 2 indexes\r\n",
                "        if len(date_data)==1:\r\n",
                "            time = date_data[0]\r\n",
                "        else:\r\n",
                "            date = date_data[0]\r\n",
                "            time = date_data[1]\r\n",
                "        parsed_data.append([Company,date,time,Comments])\r\n",
                "\r\n",
                "    \r\n",
                "\r\n",
                "# print(parsed_data) remember the parsed data is a list of lists\r\n",
                "\r\n",
                "df = pd.DataFrame(parsed_data, columns=['Company','Date','Time','Comments'])\r\n",
                "# Analyse your text\r\n",
                "vader = SentimentIntensityAnalyzer()\r\n",
                "# When we run polarity, we get a couple of key values from the result dictionary\r\n",
                "# 'neg', 'neu', 'pos', 'compound'\r\n",
                "# We can pull out what ever we want to analyse from this dictionary\r\n",
                "# Create a function and get just the compound score\r\n",
                "# Then use the apply function to run this function\r\n",
                "function = lambda x: vader.polarity_scores(x)['compound']\r\n",
                "# We want to loop through our comments column\r\n",
                "df['Compound'] = df['Comments'].apply(function)\r\n",
                "# Convert date column to date time\r\n",
                "df['Date'] = pd.to_datetime(df.Date).dt.date\r\n",
                "\r\n",
                "\r\n",
                "plt.figure(figsize=(6,8))\r\n",
                "# Using groupby makes us to have one date entry\r\n",
                "mean_df = df.groupby(['Company','Date']).mean()\r\n",
                "# Allow us to have date as x-axis\r\n",
                "mean_df = mean_df.unstack()\r\n",
                "# Remove compound column\r\n",
                "mean_df = mean_df.xs('Compound', axis='columns').transpose()\r\n",
                "mean_df.plot(kind='bar')\r\n",
                "plt.show()\r\n",
                "# print(mean_df)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "\r\n",
                "# Getting subset\r\n",
                "results = df.loc[(df['Company'] =='FB') & (df['Compound'] > 0) ,['Compound','Comments']]\r\n",
                "print(results)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# Using query method\r\n",
                "\r\n",
                "df = df[['Compound','Comments','Company']].query(\"Company==['FB','GOOG']\")\r\n",
                "df.to_csv('example.csv')\r\n",
                "print(df)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# Map\r\n",
                "# Map does not work on an entire dataframe but on a series e.g a column\r\n",
                "data = pd.DataFrame({\"power_level\": [12000, 16000, 4000, 1500, 3000, \r\n",
                "                                     2000, 1600, 2000],\r\n",
                "                     \"uniform color\": [\"orange\", \"blue\", \"black\", \"orange\",\r\n",
                "                                       \"purple\", \"green\", \"orange\", \"orange\"],\r\n",
                "                     \"species\": [\"saiyan\",\"saiyan\",\"saiyan\",\"half saiyan\",\r\n",
                "                                 \"namak\",\"human\",\"human\",\"human\"]}, \r\n",
                "                     index = [\"Goku\",\"Vegeta\", \"Nappa\",\"Gohan\",\r\n",
                "                                   \"Piccolo\",\"Tien\",\"Yamcha\", \"Krillin\"])\r\n",
                "\r\n",
                "# Use .map() to apply a function to a pandas Series\r\n",
                "# Data Frame columns are Series\r\n",
                "\r\n",
                "def my_function(x):\r\n",
                "    if x > 10000:\r\n",
                "        return(\"high\")\r\n",
                "    if x > 2000:\r\n",
                "        return(\"med\")\r\n",
                "    return (\"low\")\r\n",
                "\r\n",
                "\r\n",
                "data[\"power_level\"].map(my_function)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# To map Series values based on key: value correspondence\r\n",
                "# Pass a mapping dictionary to .map() \r\n",
                "correspondence = {\"saiyan\": \"alien\", \r\n",
                "                  \"namak\":\"alien\", \r\n",
                "                  \"human\":\"earthling\", \r\n",
                "                  \"half saiyan\": \"earthling\"}\r\n",
                "\r\n",
                "data[\"species\"].map(correspondence)"
            ],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.9.6",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.9.6 64-bit"
        },
        "interpreter": {
            "hash": "b4474bd39aa979d9034cf80f10e2f11f4a0fc3802d205559d129ca421827463e"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}