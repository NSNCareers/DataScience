{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "b4474bd39aa979d9034cf80f10e2f11f4a0fc3802d205559d129ca421827463e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi linear Regession\n",
    "# Assumptions\n",
    "# Linearity\n",
    "# Homoscedasticity\n",
    "# Multivariate normality\n",
    "# Independence of errors\n",
    "# Lack of multicollinearity\n",
    "# y = constant (b0) + b1X1 + b2X2 + b3X3 + ???\n",
    "# In this model, our State is the dummy variable\n",
    "\n",
    "# Building a model ( Backward Elimination)\n",
    "# 1) select significance level to stay in the model (eg SL=0.005)\n",
    "# 2) Fit the model wit all possible predictors\n",
    "# 3) Consider the predictor with the highest P-value. If P > SL, go to Step 4, otherwise go to Fin\n",
    "# 4) Remove the predictor\n",
    "# 5) Fit models without this variable\n",
    "\n",
    "# Building a model ( Forward Elimination)\n",
    "# 1) select significance level to enter in the model (eg SL=0.005)\n",
    "# 2) Fit all simple regression models y~xn Select the one with the lowest P-value\n",
    "# 3) Keep this variable and fit all possible models with one extra predictor added to the ones you already have\n",
    "# 4) Consider the predictor with the lowest P-value. If P < SL, go to Step three, otherwise go to Fin\n",
    "# 5) Fit models without this variable\n",
    "\n",
    "# Building a model ( Bidirectional Elimination)\n",
    "# 1) select a significance level to enter or stay in the model (eg SLenter=0.05, SLstay=0.05)\n",
    "# 2) Perform the next step of forward selection (new variables ,ust have: P < SLenter to enter)\n",
    "# 3) Perform all steps of backward elimination (old variables ,ust have: P < SLstay to stay)\n",
    "# 4) No new variable can enter and no old variable can exit\n",
    "\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependent and Independent variables\n",
    "\n",
    "dataset = pd.read_csv('data\\50_Startups.csv')\n",
    "x = dataset.iloc[:, :-1].values # : means the range and -1 means less the last column\n",
    "y = dataset.iloc[:,-1].values\n",
    "# y = dataset['Profit'].values\n",
    "# print(dataset)\n",
    "# print(x)\n",
    "# print(y)\n",
    "# print(x.shape)\n",
    "# print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataframe for missing values\n",
    "\n",
    "# dataset.fillna(0, inplace=True) # This is to fill out 0 for all missing values\n",
    "\n",
    "missing = dataset.isnull().sum()\n",
    "print(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the independent variables\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ct = ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[3])],remainder='passthrough') # Pass through will not encode the other columns. [3] represents index to encode\n",
    "x = np.array(ct.fit_transform(x))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into Training and Test set\n",
    "# To measure if the model is good enough, we can use a method called Train/Test.\n",
    "# Train/Test is a method to measure the accuracy of your model.\n",
    "# It is called Train/Test because you split the the data set into two sets: a training set and a testing set.\n",
    "# 80% for training, and 20% for testing.\n",
    "# You train the model using the training set.\n",
    "# You test the model using the testing set.\n",
    "# Train the model means create the model.\n",
    "# Test the model means test the accuracy of the model.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=1)\n",
    "\n",
    "print(x_train)\n",
    "#print(x_test)\n",
    "print(y_train)\n",
    "#print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainig the multi Linear regresion model on the training set\n",
    "# Dummy variable trap ???\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the Test set results\n",
    "# Here we are analysing the predicted vs the actual test data\n",
    "# Our results show the predicted vs the real profits\n",
    "\n",
    "y_pred = regressor.predict(x_test) # predicted profits using data from the test set\n",
    "np.set_printoptions(precision=2)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1),y_test.reshape(len(y_test),1)),1)) # Just 1 column. 0 = vertical axis and 1 = horizontal axis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising training test results\n",
    "\n",
    "plt.scatter(x_train[:,0],y_train, color = 'red')\n",
    "plt.plot(x_train,regressor.predict(x_train),color = 'blue')\n",
    "plt.title('Expense vs Profit (Training set)')\n",
    "plt.xlabel('Expected profit')\n",
    "plt.ylabel('Expected cost')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising training train results\n",
    "\n",
    "plt.scatter(x_test[:,0],y_test, color = 'red')\n",
    "plt.plot(x_train,regressor.predict(x_train),color = 'blue')\n",
    "plt.title('Expense vs Profit (T est set)')\n",
    "plt.xlabel('Expected profit')\n",
    "plt.ylabel('Expected cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "ols = linear_model.LinearRegression()\n",
    "model = ols.fit(x, y)\n",
    "model.coef_ # The linear regression coefficient can be accessed in a form of class attribute with model.coef_\n",
    "model.intercept_ # The y-intercept can be accessed in a form of class attribute with model.intercept_\n",
    "model.score(x, y) # How good was your model? You can evaluate your model performance in a form of R-squared, with model.score(X, y). X is the features, and y is the response variable used to fit the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}